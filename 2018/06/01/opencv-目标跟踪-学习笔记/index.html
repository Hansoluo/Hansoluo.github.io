<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="The dream of love and hope shall never die"><title>opencv_目标跟踪_学习笔记 | Hansoluo's blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">opencv_目标跟踪_学习笔记</h1><a id="logo" href="/.">Hansoluo's blog</a><p class="description">醉舟的博客</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">opencv_目标跟踪_学习笔记</h1><div class="post-meta">Jun 1, 2018</div><a class="disqus-comment-count" data-disqus-identifier="2018/06/01/opencv-目标跟踪-学习笔记/" href="/2018/06/01/opencv-目标跟踪-学习笔记/#disqus_thread"></a><div class="post-content"><p>本文是图书 <a href="https://book.douban.com/subject/26816975/" target="_blank" rel="external">OpenCV 3计算机视觉</a> 第8章（目标跟踪）的学习笔记。<br><a id="more"></a></p>
<h2 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h2><p>目标跟踪是对对摄像头的移动目标进行定位的过程，主要分为如何检测移动物体和跨帧跟踪两方面。</p>
<p>实时的目标跟踪可以应用于监控(Surveillance)、基于感知(perceptual)的用户界面、增强现实、基于对象的视频压缩以及辅助驾驶等。</p>
<p>目标跟踪的实现方式很多，但是最优的跟踪技术和具体任务有关。</p>
<h2 id="如何检测移动目标"><a href="#如何检测移动目标" class="headerlink" title="如何检测移动目标"></a>如何检测移动目标</h2><ul>
<li>目的不同，方法不同<ul>
<li>需要跟踪画面中所有移动的目标，帧与帧之间的差异比较重要，采用背景减除(Background Subtraction)法</li>
<li>需要跟踪视频中移动的手时，基于皮肤颜色的均值漂移(MeanShift)方法最好</li>
<li>需要跟踪对象某一方面时，可采用模板匹配</li>
</ul>
</li>
</ul>
<h3 id="背景减除-Background-Subtraction"><a href="#背景减除-Background-Subtraction" class="headerlink" title="背景减除(Background Subtraction)"></a>背景减除(Background Subtraction)</h3><h4 id="简单的例子：计算帧与帧之间的差异"><a href="#简单的例子：计算帧与帧之间的差异" class="headerlink" title="简单的例子：计算帧与帧之间的差异"></a>简单的例子：计算帧与帧之间的差异</h4><ul>
<li><p>计算差异，并对图像进行预处理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">diff = cv2.absdiff(background, gray_frame) # 得到差分图</div><div class="line">diff = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1] # 应用阈值得到黑白图像</div><div class="line">diff = cv2.dilate(diff, es, iterations = 2) # 侵蚀和膨胀</div></pre></td></tr></table></figure>
</li>
<li><p>对得到的图像后处理，标识移动的目标</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">image, cnts, hierarchy = cv2.findContours(diff.copy(),</div><div class="line">    cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE) # 找到图像中物体的轮廓</div><div class="line">for c in cnts:</div><div class="line">    if cv2.contourAera(c) &lt; 1500:</div><div class="line">        continue  # 给定轮廓的阈值，过滤掉微小的变化</div><div class="line">    (x,y,w,h) = cv2.boundingRect(c) # 给定区域，计算边界框坐标</div><div class="line">    cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 255, 0), 2) # 标识移动目标</div></pre></td></tr></table></figure>
</li>
<li><p>不足：需要默认帧作为背景，如果光照变化频繁，因为有阴影的存在，处理效果较差</p>
</li>
</ul>
<h4 id="背景分割器：-KNN、MOG2和GMG"><a href="#背景分割器：-KNN、MOG2和GMG" class="headerlink" title="背景分割器： KNN、MOG2和GMG"></a>背景分割器： KNN、MOG2和GMG</h4><ul>
<li>提高背景分割器的精度<ul>
<li>采用KNN或者高斯分布的方法对背景进行建模</li>
<li>GMG可以对前120帧进行学习，MOG2可以使用前20帧或者更多的进行训练</li>
<li>增加阴影检测，帮助减少阴影的干扰</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">bs = cv2.createBackgroundSubtractorMOG2(detectShadows=True) # 构建背景分割器</div><div class="line">fg_mask = bs.apply(frame)  # 执行背景分割</div></pre></td></tr></table></figure>
<h3 id="均值漂移和CAMShift"><a href="#均值漂移和CAMShift" class="headerlink" title="均值漂移和CAMShift"></a>均值漂移和CAMShift</h3><ul>
<li><p>Meanshift算法依赖于直方图，给定ROI区域后，先计算出最大灰度密度，并且重新计算在下一帧中的最大密度，如此就给出了目标的移动方向</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 ) # 设置迭代10次后收敛</div><div class="line">ret, track_window = cv2.meanShift(dst, track_window, term_crit) # 应用</div></pre></td></tr></table></figure>
</li>
<li><p>缺点： 开始设置的ROI窗口是固定的，但是视频中物体由远及近是一个逐渐变大的过程，所以再采用固定窗口是不合适的</p>
</li>
<li>CAMshift 可以解决上述问题，在 Meanshift 的基础上，调整目标框的大小和角度<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ret, track_window = cv2.CamShift(dst, track_window, term_crit) # 应用</div><div class="line"># Draw it on image</div><div class="line">pts = cv2.boxPoints(ret)</div><div class="line">pts = np.int0(pts)</div><div class="line">img2 = cv2.polylines(frame,[pts],True, 255,2)</div><div class="line">cv2.imshow(&apos;img2&apos;,img2)</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="卡尔曼滤波器"><a href="#卡尔曼滤波器" class="headerlink" title="卡尔曼滤波器"></a>卡尔曼滤波器</h3><ul>
<li>(stage1)预测： 使用当前点计算的协方差来估计目标的新位置  <code>kalman.predict()</code></li>
<li>(stage2)更新： 记录目标的位置，并为下一次循环计算修正的协方差 <code>kalman.correct()</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">kalman = cv2.KalmanFilter(4,2) # 设置卡尔曼滤波器</div><div class="line">kalman.correct(current_measurement) # 用当前位置去纠正卡尔曼</div><div class="line">current_prediction = kalman.predict() # 预测下一步位置</div></pre></td></tr></table></figure>
<h2 id="行人跟踪的实例"><a href="#行人跟踪的实例" class="headerlink" title="行人跟踪的实例"></a>行人跟踪的实例</h2><ul>
<li>工作流程：<ul>
<li>检查前面几帧，作为背景，构建背景分割器识别运动物体</li>
<li>对运动物体提取ROI，进行物体识别，是否为行人</li>
<li>识别的行人加入追踪列表，并利用 kalman/CAMShift 来跟踪行人ID</li>
<li>检查下一帧是否有进入场景的新行人</li>
</ul>
</li>
</ul>
<h3 id="其他参考文档"><a href="#其他参考文档" class="headerlink" title="其他参考文档"></a>其他参考文档</h3><ul>
<li><a href="http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_meanshift/py_meanshift.html#meanshift" target="_blank" rel="external">opencv-meanshift</a></li>
<li><a href="http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_bg_subtraction/py_bg_subtraction.html#background-subtraction" target="_blank" rel="external">opencv-background-subtraction</a></li>
</ul>
<h3 id="changelog"><a href="#changelog" class="headerlink" title="changelog"></a>changelog</h3><ul>
<li>20180601 init</li>
<li>20180604 V1.0</li>
</ul>
</div><div class="tags"><a href="/tags/opencv/">opencv</a><a href="/tags/目标跟踪/">目标跟踪</a></div><div class="post-nav"><a class="pre" href="/2018/06/02/FaceNet-论文笔记/">FaceNet-论文笔记</a><a class="next" href="/2018/05/24/R-FCN-论文笔记/">R-FCN 论文笔记</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://hansoluo.github.io/2018/06/01/opencv-目标跟踪-学习笔记/';
    this.page.identifier = '2018/06/01/opencv-目标跟踪-学习笔记/';
    this.page.title = 'opencv_目标跟踪_学习笔记';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//hansoluo.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//hansoluo.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://hansoluo.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://hansoluo.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/目标跟踪/" style="font-size: 15px;">目标跟踪</a> <a href="/tags/生活/" style="font-size: 15px;">生活</a> <a href="/tags/图像识别/" style="font-size: 15px;">图像识别</a> <a href="/tags/目标检测/" style="font-size: 15px;">目标检测</a> <a href="/tags/人脸识别/" style="font-size: 15px;">人脸识别</a> <a href="/tags/opencv/" style="font-size: 15px;">opencv</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/故事/" style="font-size: 15px;">故事</a> <a href="/tags/读书/" style="font-size: 15px;">读书</a> <a href="/tags/自我管理/" style="font-size: 15px;">自我管理</a> <a href="/tags/观影/" style="font-size: 15px;">观影</a> <a href="/tags/音乐/" style="font-size: 15px;">音乐</a> <a href="/tags/工具/" style="font-size: 15px;">工具</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/06/2019-m1-w1一周总结/">2019-m1-w1</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/03/opencv-6种目标跟踪算法概述/">opencv_6种目标跟踪算法概述</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/02/FaceNet-论文笔记/">FaceNet-论文笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/01/opencv-目标跟踪-学习笔记/">opencv_目标跟踪_学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/24/R-FCN-论文笔记/">R-FCN 论文笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/20/YOLO-论文笔记/">YOLO-论文笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/17/道路车辆实时检测-实践/">道路车辆实时检测实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/16/SSD-论文笔记/">SSD 论文笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/16/Faster-RCNN-论文笔记/">Faster R-CNN 论文笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/13/Bird-Species-Categorization-Using-Pose-论文笔记/"><利用姿态归一深度卷积网络实现鸟分类> 论文笔记</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//hansoluo.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.yangzhiping.com/" title="阳志平的网志" target="_blank">阳志平的网志</a><ul></ul><a href="http://www.paulgraham.com/articles.html" title="paulgraham" target="_blank">paulgraham</a><ul></ul><a href="http://wiki.zoomquiet.io/IMHO/om-how2b-dama" title="zoomquiet" target="_blank">zoomquiet</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Hansoluo's blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>